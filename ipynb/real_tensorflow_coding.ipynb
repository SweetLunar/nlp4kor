{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이 문서는 초보가 제작하였으므로, 틀린 부분이 있을 지도 모릅니다.\n",
    "- https://github.com/bage79/nlp4kor\n",
    "- https://www.youtube.com/playlist?list=PLE_yleP-KQefhFSNh16hJKnq6stIG05fu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Tensorflow Coding\n",
    "- 대용량 입력 데이터\n",
    "- 학습 모델 저장/로드\n",
    "- 최적의 모델 선택\n",
    "- 반복 학습 (그래프 재사용)\n",
    "\n",
    "### Reference\n",
    "- https://www.buzzvil.com/2017/02/22/buzzvil-techblog-tensorflow-deeplearning/\n",
    "- https://jasdeep06.github.io/posts/variable-sharing-in-tensorflow/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queue Runner (input pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (질문1) tensorflow 학습중에, 파이썬 프로그램이 멈춰버린 적이 있나요?\n",
    "<img src=\"img/gpu_out_of_memory.png\">\n",
    "- https://3.bp.blogspot.com/-PSbzKHlUR9U/VxQ659ilhPI/AAAAAAAABuQ/CB33z-iJxMMrVLVECnIqe5xUUvKBKyE3ACKgB/s1600/step04.png\n",
    "- standard output (out of GPU memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (질문2) tensorflow 데이터 로딩중에, 파이썬 프로그램이 멈춰버린 적이 있나요?\n",
    "<img src=\"img/out_of_memory_syslog.png\">\n",
    "- /var/log/syslog (out of RAM memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (질문3) tensorflow로 학습시킬 때 GPU 사용량이 불규칙 적인 것을 보셨나요?\n",
    "<img src=\"img/nvidia-smi.png\">\n",
    "- watch -n 1 nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why you need Tensorflow Queue Runner\n",
    "- for better Performance\n",
    "    - parallel data loading in other python thread\n",
    "\n",
    "<img src=\"img/why_need_queue_runner.png\">\n",
    "- https://www.quora.com/In-TensorFlow-what-are-queue-runners-and-why-are-they-useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods of reading data\n",
    "- https://www.tensorflow.org/programmers_guide/reading_data\n",
    "- 1.Preloaded data: \n",
    "    - a constant or variable in the TensorFlow graph holds all the data (for small data sets).\n",
    "- 2.Feeding: \n",
    "    - Python code provides the data when running each step.\n",
    "    - tf.placeholder(shape)\n",
    "- 3.Reading from files: (for large data sets).\n",
    "    - an input pipeline reads the data from files at the beginning of a TensorFlow graph.\n",
    "    - tf.train.string_input_producer(filenames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reading from files (Queue Runner)\n",
    "<img src=\"img/queue_runner_process.gif\">\n",
    "https://www.tensorflow.org/programmers_guide/reading_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/queue_runner_bcho.png\">\n",
    "http://bcho.tistory.com/1165"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Fast with placeholder & feed_dict (preloaded small data)\n",
    "```python\n",
    "all_data = None # preloaded small data in memory\n",
    "def next_batch_in_memory(filenames, batch_size):\n",
    "    all_data = read_all_data_into_memory(filenames)\n",
    "    for features_batch, labels_batch in all_data:\n",
    "        yield features_batch, labels_batch\n",
    "def create_graph():\n",
    "    x = tf.placeholder()\n",
    "    y = tf.placeholder()\n",
    "    return x, y\n",
    "x, y = create_graph()\n",
    "with tf.Session():\n",
    "    for features_batch, labels_batch in next_batch_in_memory(filenames):\n",
    "        _train_cost, _train_step = sess.run([train_cost, train_step], \n",
    "                                            feed_dict={x:_features_batch, y: _labels_batch})    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast with placeholder & feed_dict (for big data)\n",
    "```python\n",
    "def next_batch(filenames, batch_size):\n",
    "    for file in filenames:\n",
    "        features_batch, labels_batch = [], []\n",
    "        for line in file:\n",
    "            feature, label = line.split()\n",
    "            features_batch.append(feature)\n",
    "            labels_batch.append(label)\n",
    "            if len(features_batch) >= batch_size:\n",
    "                yield features_batch, labels_batch\n",
    "                features_batch, labels_batch = [], []\n",
    "def create_graph():\n",
    "    x = tf.placeholder()\n",
    "    y = tf.placeholder()\n",
    "    return x, y\n",
    "x, y = create_graph()\n",
    "with tf.Session():\n",
    "    for features_batch, labels_batch in next_batch(filenames):\n",
    "        _train_cost, _train_step = sess.run([train_cost, train_step], \n",
    "                                            feed_dict={x:_features_batch, y: _labels_batch})    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But...\n",
    "### My Queue Runner is very slower than placeholder. Why?\n",
    "### (Reason) use free_dict for data\n",
    "- Very Slow with Queue Runner & feed_dict (incorrect way)\n",
    "```python\n",
    "def input_pipeline(filenames):\n",
    "    filename_queue = tf.train.string_input_producer([filenames], shuffle=False)\n",
    "    reader = tf.TextReader()\n",
    "    _, line = reader.read()\n",
    "    tokens = tf.decode_csv(line)\n",
    "    feature, label = tf.reshape(tokens[:-1], ), tf.reshape(tokens[-1], )\n",
    "    features_batch, labels_batch = tf.train.batch([feature, label])\n",
    "    return features_batch, labels_batch\n",
    "def create_graph():\n",
    "    x = tf.placeholder()\n",
    "    y = tf.placeholder()\n",
    "    return x, y\n",
    "x, y = create_graph()\n",
    "features_batch, labels_batch = input_pipeline(filenames)\n",
    "with tf.Session():\n",
    "    for nth_batch in range(n_train//batch_size):\n",
    "        _features_batch, _labels_batch = sess.run([features_batch, labels_batch]) # read from queue\n",
    "        _train_cost, _train_step = sess.run([train_cost, train_step], feed_dict={x:_features_batch, y: _labels_batch}) # input to placeholder\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Fast with Queue Runner (for big data)\n",
    "```python\n",
    "def input_pipeline(filenames):\n",
    "    # same with above\n",
    "    return features_batch, labels_batch\n",
    "def create_graph(x, y):\n",
    "    x, y = input_pipeline(filenames)\n",
    "    return x, y\n",
    "x, y = create_graph()\n",
    "with tf.Session():\n",
    "    _train_cost, _train_step = sess.run([train_cost, train_step])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Queue Runner & placeholder\n",
    "##### with placeholder & preload (Very Fast, small data)\n",
    "<img src=\"img/learn_add_with_placeholder_preload.png\">\n",
    "##### with placeholder (Fast)\n",
    "<img src=\"img/learn_add_with_placeholder.png\">\n",
    "##### with Queue Runner & feed_dict (Very Slow)\n",
    "- incorrect way\n",
    "<img src=\"img/learn_add_with_queue_feed_dict.png\">\n",
    "##### with Queue Runner (Very Fast)\n",
    "<img src=\"img/learn_add_with_queue.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Save & Load\n",
    "- tf.train.Saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model_name = os.path.basename(__file__).replace('.py', '')\n",
    "model_file = os.path.join(MODELS_DIR, '%s.n_train_%s.batch_size_%s.total_train_time_%s/model' % (model_name, n_train, batch_size, total_train_time))\n",
    "model_dir = os.path.dirname(model_file)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "합계 68\r\n",
      "drwxrwxr-x 17 bage bage 4096 Jul 29 14:10 .\r\n",
      "drwxrwxr-x 10 bage bage 4096 Jul 24 16:33 ..\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 29 22:14 learn_add_with_placeholder.n_train_1000.batch_size_1.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 29 22:14 learn_add_with_placeholder.n_train_1000.batch_size_10.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 29 22:14 learn_add_with_placeholder.n_train_1000.batch_size_100.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 29 13:03 learn_add_with_placeholder_preload.n_train_1000.batch_size_1.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 29 13:03 learn_add_with_placeholder_preload.n_train_1000.batch_size_10.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 29 13:03 learn_add_with_placeholder_preload.n_train_1000.batch_size_100.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 29 22:21 learn_add_with_queue.n_train_1000.batch_size_1.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 29 22:21 learn_add_with_queue.n_train_1000.batch_size_10.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 29 22:21 learn_add_with_queue.n_train_1000.batch_size_100.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 28 22:50 learn_add_with_queue_and_feed_dict.n_train_1000.batch_size_1.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 28 22:50 learn_add_with_queue_and_feed_dict.n_train_1000.batch_size_10.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 28 22:50 learn_add_with_queue_and_feed_dict.n_train_1000.batch_size_100.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 28 11:04 learn_add_with_queue_with_cond.n_train_1000.batch_size_1.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 28 11:04 learn_add_with_queue_with_cond.n_train_1000.batch_size_10.total_train_time_5\r\n",
      "drwxrwxr-x  2 bage bage 4096 Jul 28 11:04 learn_add_with_queue_with_cond.n_train_1000.batch_size_100.total_train_time_5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al /home/bage/workspace/nlp4kor/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "saver = tf.train.Saver(max_to_keep=None)\n",
    "for epoch in range(total_epochs): # (optional) save model on each epoch\n",
    "    saver.save(sess, model_file, global_step=epoch)\n",
    "\n",
    "if min_valid_epoch == epoch:  # save the lastest best model \n",
    "    saver.save(sess, model_file)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "if not training_mode and checkpoint: # this is test mode and model exists\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, model_file) # restore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (주의) 위와 같은 방법으로 best model을 찾지 못하는 경우 \n",
    "- 동영상 발표 참고\n",
    "- 따라서, Tensorboard를 통하여 min valid cost가 정상적으로 학습된 Weight에 의한 값인지 눈으로 확인할 필요 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current code line is running on CPU or GPU? (발표 동영상 참고)\n",
    "- x = tf.placeholder(...)\n",
    "- sess.run(tf.global_variables_initializer())\n",
    "- _cost = sess.run([cost], feed_dict={x: x_data})\n",
    "- Saver().save(model_file)\n",
    "- Saver().restore(model_file)\n",
    "- http://haanjack.github.io/cuda/2016-02-16-CUDA/\n",
    "<img src=\"img/cuda_processing_flow.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "- https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/tensorboard/README.md\n",
    "- https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/4_Utils/tensorboard_basic.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start & stop Tensorboard background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alias tensorboard-clear='rm -rf ~/tensorboard_log/*'\r\n",
      "alias tensorboard-start='nohup tensorboard --reload_interval=5 --logdir=~/tensorboard_log/ --port=6006 >/dev/null 2>&1 &'\r\n",
      "alias tensorboard-stop='pkill -f tensorboard && sleep 1 && ps aux | grep tensorboard | grep -v grep'\r\n"
     ]
    }
   ],
   "source": [
    "!grep tensorboard ~/.bash_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bage      4049     1  0 10:18 ?        00:00:09 /home/bage/anaconda3/bin/python /home/bage/anaconda3/bin/tensorboard --reload_interval=5 --logdir=~/tensorboard_log/ --port=6006\r\n"
     ]
    }
   ],
   "source": [
    "!ps -efww | grep tensorboard | grep -v grep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Graph by different Batch-sizes\n",
    "<img src=\"img/learn_add_with_placeholder_tensorboard.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuse Graph\n",
    "- 1.train & valid graph\n",
    "- 2.graph with different hypter-parameters\n",
    "- https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/how_tos/variable_scope/\n",
    "```python\n",
    "def create_graph(reuse=None):\n",
    "    with tf.variable_scope('model', reuse=reuse) as scope: # reuse variables while entring into this scope\n",
    "        # w = tf.Variable(\"w1\", shape, initializer=tf.random_normal_initializer())\n",
    "        w = tf.get_variable(\"w1\", shape, initializer=tf.random_normal_initializer()) # name=model/w1\n",
    "        scope.reuse_variables() # reuse already defined variables in this scope\n",
    "        w = tf.get_variable(\"w1\", shape, initializer=tf.random_normal_initializer()) # name=model/w1\n",
    "train_cost, train_step = create_graph(reuse=None)\n",
    "valid_cost = create_graph(reuse=True)\n",
    "test_cost, accuracy, y_hat = create_graph(reuse=True)\n",
    "with tf.Session():\n",
    "    if is_training:\n",
    "        _train_cost, _train_step = sess.run([train_cost, train_step]) # x, y is feeded from pipeline\n",
    "        _valid_cost = sess.run([valid_cost]) # x, y is feeded from pipeline\n",
    "    else:\n",
    "        _test_cost, _accuracy, _y_hat, _w = sess.run([test_cost, accuracy, y_hat, w]) # x, y is feeded from pipeline\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Tip) Multiple session on one GPU\n",
    "```python\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # do not use entire memory for this session\n",
    "with tf.Session(config=config) as sess:\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Tip) Tensor's Flow (classification)\n",
    "- http://machinethink.net/blog/tensorflow-on-ios/\n",
    "<img src=\"img/tensorflow_classifitation_process.png\">\n",
    "- cost(loss) function\n",
    "    - binary classification: sigmoid\n",
    "    - multi-label classification: softmax with cross entropy\n",
    "- y_pred (y_hat): for calculating cost\n",
    "- inference (predicted label): for accucary\n",
    "##### train vs valid vs test\n",
    "- train: optimizer(minimize or maximize)\n",
    "- valid: cost\n",
    "- test: cost & accuracy & w, b, y_hat ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Tensorflow Coding\n",
    "- 대용량 입력 데이터: Queue Runner (Input Pipeline)\n",
    "- 학습 모델 저장/로드: Saver\n",
    "- 최적의 모델 선택: Tensorboard (Check epoch has minimum valid cost)\n",
    "- 반복 학습 (그래프 재사용): tf.variable_scope(reuse=True) & tf.get_variable(name='') & scop.reuse_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### (Example) Learn Add function (Linear Regression)\n",
    "- https://github.com/bage79/nlp4kor/blob/master/nlp4kor/examples/learn_add_with_placeholder.py\n",
    "    - with placeholder & feed_dict\n",
    "- https://github.com/bage79/nlp4kor/blob/master/nlp4kor/examples/learn_add_with_queue.py\n",
    "    - with Queue Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 /home/bage/workspace/nlp4kor/data/add.train.tsv\n",
      "100 /home/bage/workspace/nlp4kor/data/add.valid.tsv\n",
      "100 /home/bage/workspace/nlp4kor/data/add.test.tsv\n"
     ]
    }
   ],
   "source": [
    "!wc -l /home/bage/workspace/nlp4kor/data/add.train.tsv\n",
    "!wc -l /home/bage/workspace/nlp4kor/data/add.valid.tsv\n",
    "!wc -l /home/bage/workspace/nlp4kor/data/add.test.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\t26\t71\r\n",
      "50\t14\t64\r\n",
      "75\t78\t153\r\n",
      "44\t0\t44\r\n",
      "45\t64\t109\r\n",
      "40\t65\t105\r\n",
      "90\t27\t117\r\n",
      "92\t79\t171\r\n",
      "49\t84\t133\r\n",
      "78\t5\t83\r\n"
     ]
    }
   ],
   "source": [
    "!head /home/bage/workspace/nlp4kor/data/add.train.tsv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
